{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, I will use the Scikit-Learn library to fit a Support Vector Machine Classifier to the Iris Flower Dataset \n",
    "# (using 3 binary classifiers and then 1 multiclass classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "iris_data = datasets.load_iris()\n",
    "iris_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the predictors and the target variable\n",
    "X = iris_data['data']\n",
    "Y = iris_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.] \n",
      " [1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create the train and test set for each classifier\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "train_set_size = int(0.8*len(X))\n",
    "\n",
    "X_train = X[shuffled_indices[:train_set_size]]\n",
    "X_test = X[shuffled_indices[train_set_size:]]\n",
    "Y_train = Y[shuffled_indices[:train_set_size]]\n",
    "Y_test = Y[shuffled_indices[train_set_size:]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# For the Iris Setosa detector\n",
    "Y_train1 = (Y[shuffled_indices[:train_set_size]] == 0).astype(np.float64)\n",
    "Y_test1 = (Y[shuffled_indices[train_set_size:]] == 0).astype(np.float64)\n",
    "# For the Iris Versicolor detector\n",
    "Y_train2 = (Y[shuffled_indices[:train_set_size]] == 1).astype(np.float64)\n",
    "Y_test2 = (Y[shuffled_indices[train_set_size:]] == 1).astype(np.float64)\n",
    "# For the Iris Virginica detector\n",
    "Y_train3 = (Y[shuffled_indices[:train_set_size]] == 2).astype(np.float64)\n",
    "Y_test3 = (Y[shuffled_indices[train_set_size:]] == 2).astype(np.float64)\n",
    "\n",
    "print(Y_train1[:20], '\\n', Y_train2[:20], '\\n', Y_train3[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to run a grid search or not\n",
    "run_grid_search = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'loss': 'hinge', 'max_iter': 5000}\n",
      "{'C': 10, 'loss': 'hinge', 'max_iter': 5000}\n",
      "{'C': 1, 'loss': 'hinge', 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# If True, run a grid search, or create 3 LinearSVC models for detecting each class\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "if run_grid_search:\n",
    "    param_grid = [\n",
    "        {'C': [0.01, 0.1, 1, 1.0, 10], 'loss': ['hinge'], 'max_iter': [5000]},\n",
    "    ]\n",
    "\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "    grid_search1 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "    grid_search2 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "    grid_search3 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "\n",
    "    grid_search1.fit(X_train, Y_train1)\n",
    "    grid_search2.fit(X_train, Y_train2)\n",
    "    grid_search3.fit(X_train, Y_train3)\n",
    "\n",
    "    svm_clf1 = grid_search1.best_estimator_\n",
    "    svm_clf2 = grid_search2.best_estimator_\n",
    "    svm_clf3 = grid_search3.best_estimator_\n",
    "\n",
    "    print(grid_search1.best_params_)\n",
    "    print(grid_search2.best_params_)\n",
    "    print(grid_search3.best_params_)\n",
    "    \n",
    "else:\n",
    "    # Create a model for each class (binary classifiers)\n",
    "    svm_clf1 = LinearSVC(C=0.1,loss='hinge', max_iter = 5000)\n",
    "\n",
    "    svm_clf2 = LinearSVC(C=10, loss='hinge', max_iter = 5000)\n",
    "\n",
    "    svm_clf3 = LinearSVC(C=0.1, loss='hinge', max_iter = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the models to the data\n",
    "\n",
    "# Iris Setosa vs All\n",
    "svm_clf1.fit(X_train,Y_train1)\n",
    "Y_test1_predictions = svm_clf1.predict(X_test)\n",
    "# Iris Versicolor vs All\n",
    "svm_clf2.fit(X_train,Y_train2)\n",
    "Y_test2_predictions = svm_clf2.predict(X_test)\n",
    "# Iris Virginica vs ALl\n",
    "svm_clf3.fit(X_train,Y_train3)\n",
    "Y_test3_predictions = svm_clf3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIVIDUAL CLASS PERFORMANCE WITH A LINEAR KERNEL \n",
      "\n",
      "Iris Setosa\n",
      "\t Accuracy:  1.0\n",
      "\t Precision:  1.0\n",
      "\t Recall:  1.0\n",
      "\t F1-Score:  1.0\n",
      "\t Confusion Matrix:  \n",
      "\t [[21, 0], [0, 9]]\n",
      "Iris Versicolor\n",
      "\t Accuracy:  0.7\n",
      "\t Precision:  0.5\n",
      "\t Recall:  0.3333333333333333\n",
      "\t F1-Score:  0.4\n",
      "\t Confusion Matrix:  \n",
      "\t [[18, 3], [6, 3]]\n",
      "Iris Virginica\n",
      "\t Accuracy:  0.9666666666666667\n",
      "\t Precision:  0.9230769230769231\n",
      "\t Recall:  1.0\n",
      "\t F1-Score:  0.9600000000000001\n",
      "\t Confusion Matrix:  \n",
      "\t [[17, 1], [0, 12]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Test Set performance for all 3 models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,  recall_score, f1_score\n",
    "\n",
    "def PerformanceMetrics(Y, Y_predicted):\n",
    "    Y = Y.flatten()\n",
    "    Y_predicted = Y_predicted.flatten()\n",
    "    \n",
    "    accuracy = accuracy_score(Y, Y_predicted)\n",
    "    cm = confusion_matrix(Y, Y_predicted)\n",
    "    precision = precision_score(Y, Y_predicted)\n",
    "    recall = recall_score(Y, Y_predicted)\n",
    "    f1 = f1_score(Y, Y_predicted)\n",
    "    return accuracy, cm, precision, recall, f1\n",
    "\n",
    "def DisplayMetrics(category, metrics):\n",
    "    print(category)\n",
    "    print('\\t','Accuracy: ', metrics[0])\n",
    "    print('\\t','Precision: ', metrics[2])\n",
    "    print('\\t','Recall: ', metrics[3])\n",
    "    print('\\t','F1-Score: ', metrics[4])\n",
    "    print('\\t','Confusion Matrix: ', '\\n\\t', metrics[1].tolist())\n",
    "\n",
    "print('Individual Class Performance With a Linear Kernel'.upper(), '\\n')\n",
    "categories = ['Iris Setosa', 'Iris Versicolor', 'Iris Virginica']\n",
    "DisplayMetrics(categories[0], tuple(PerformanceMetrics(Y_test1, Y_test1_predictions)))\n",
    "DisplayMetrics(categories[1], tuple(PerformanceMetrics(Y_test2, Y_test2_predictions)))\n",
    "DisplayMetrics(categories[2], tuple(PerformanceMetrics(Y_test3, Y_test3_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'loss': 'hinge', 'max_iter': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# If True, run a grid search, or create 1 multi-class classifier model\n",
    "if run_grid_search: \n",
    "    param_grid = [\n",
    "        {'C': [0.01, 0.1, 1, 1.0, 10], 'loss': ['hinge'], 'max_iter': [10000]},\n",
    "    ]\n",
    "\n",
    "    gridSearch = GridSearchCV(LinearSVC(), param_grid, cv = 3, scoring = 'accuracy', return_train_score = True)\n",
    "    gridSearch.fit(X_train,  Y_train)\n",
    "\n",
    "    clf = gridSearch.best_estimator_\n",
    "    print(gridSearch.best_params_)\n",
    "\n",
    "else:\n",
    "    # Build Linear Support Vector Classifier (multiclass classifier)\n",
    "    clf = LinearSVC(C = 1, loss = 'hinge', max_iter = 10000) # parameters determined from the grid search above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTICLASS CLASSIFICATION PERFORMANCE WITH A LINEAR KERNEL \n",
      "\n",
      "Accuracy:  \n",
      " 0.9333333333333333 \n",
      "\n",
      "Confusion Matrix:  \n",
      " [[ 8  1  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the train set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "Y_test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Assess model accuracy\n",
    "cm = confusion_matrix(Y_test, Y_test_predictions)\n",
    "accuracy = accuracy_score(Y_test, Y_test_predictions)\n",
    "\n",
    "print('Multiclass Classification Performance With A Linear Kernel'.upper(), '\\n')\n",
    "print('Accuracy: ', '\\n', accuracy, '\\n')\n",
    "print('Confusion Matrix: ', '\\n', cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to run grid search for the Gaussian RBF kernel\n",
    "run_grid_search_rbf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.03, 'max_iter': 5000}\n",
      "{'C': 1, 'gamma': 0.1, 'max_iter': 5000}\n",
      "{'C': 10, 'gamma': 0.03, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# If True, run a grid search, otherwise create 3 SVC models with a rbf kernel (one for each class)\n",
    "if run_grid_search_rbf:\n",
    "    param_grid = [\n",
    "        {'C': [0.01, 0.1, 1, 1.0, 10], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10], 'max_iter': [5000]},\n",
    "    ]\n",
    "\n",
    "    svm_clf = SVC()\n",
    "\n",
    "    grid_search_rbf1 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "    grid_search_rbf2 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "    grid_search_rbf3 = GridSearchCV(svm_clf, param_grid, cv = 3, scoring = 'recall', return_train_score = True)\n",
    "\n",
    "    grid_search_rbf1.fit(X_train, Y_train1)\n",
    "    grid_search_rbf2.fit(X_train, Y_train2)\n",
    "    grid_search_rbf3.fit(X_train, Y_train3)\n",
    "\n",
    "    svm_clf1_rbf = grid_search_rbf1.best_estimator_\n",
    "    svm_clf2_rbf = grid_search_rbf2.best_estimator_\n",
    "    svm_clf3_rbf = grid_search_rbf3.best_estimator_\n",
    "\n",
    "    print(grid_search_rbf1.best_params_)\n",
    "    print(grid_search_rbf2.best_params_)\n",
    "    print(grid_search_rbf3.best_params_)\n",
    "\n",
    "else:\n",
    "    # Create a model for each class (binary classifiers)\n",
    "    svm_clf1_rbf = SVC(kernel = 'rbf', C = 10, gamma = 0.1, max_iter = 5000)\n",
    "\n",
    "    svm_clf2_rbf = SVC(kernel = 'rbf', C = 1, gamma = 0.3, max_iter = 5000)\n",
    "\n",
    "    svm_clf3_rbf =SVC(kernel = 'rbf', C = 1, gamma = 0.3, max_iter = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the 3 models on the training set\n",
    "\n",
    "# Iris Setosa vs All\n",
    "svm_clf1_rbf.fit(X_train,Y_train1)\n",
    "Y_test1_predictions_rbf = svm_clf1_rbf.predict(X_test)\n",
    "# Iris Versicolor vs All\n",
    "svm_clf2_rbf.fit(X_train,Y_train2)\n",
    "Y_test2_predictions_rbf = svm_clf2_rbf.predict(X_test)\n",
    "# Iris Virginica vs ALl\n",
    "svm_clf3_rbf.fit(X_train,Y_train3)\n",
    "Y_test3_predictions_rbf = svm_clf3_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIVIDUAL CLASS PERFORMANCE WITH A GAUSSIAN RBF KERNEL \n",
      "\n",
      "Iris Setosa\n",
      "\t Accuracy:  1.0\n",
      "\t Precision:  1.0\n",
      "\t Recall:  1.0\n",
      "\t F1-Score:  1.0\n",
      "\t Confusion Matrix:  \n",
      "\t [[21, 0], [0, 9]]\n",
      "Iris Versicolor\n",
      "\t Accuracy:  0.9333333333333333\n",
      "\t Precision:  0.8181818181818182\n",
      "\t Recall:  1.0\n",
      "\t F1-Score:  0.9\n",
      "\t Confusion Matrix:  \n",
      "\t [[19, 2], [0, 9]]\n",
      "Iris Virginica\n",
      "\t Accuracy:  1.0\n",
      "\t Precision:  1.0\n",
      "\t Recall:  1.0\n",
      "\t F1-Score:  1.0\n",
      "\t Confusion Matrix:  \n",
      "\t [[18, 0], [0, 12]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the 3 models on the test set\n",
    "print('Individual Class Performance With a Gaussian RBF Kernel'.upper(), '\\n')\n",
    "categories = ['Iris Setosa', 'Iris Versicolor', 'Iris Virginica']\n",
    "DisplayMetrics(categories[0], tuple(PerformanceMetrics(Y_test1, Y_test1_predictions_rbf)))\n",
    "DisplayMetrics(categories[1], tuple(PerformanceMetrics(Y_test2, Y_test2_predictions_rbf)))\n",
    "DisplayMetrics(categories[2], tuple(PerformanceMetrics(Y_test3, Y_test3_predictions_rbf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.03, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daanish Mohammed\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# If True, run a grid search, otherwise create a multiclass SVC model\n",
    "if run_grid_search_rbf:\n",
    "    param_grid = [\n",
    "        {'C': [0.01, 0.1, 1, 1.0, 10], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10], 'max_iter': [5000]},\n",
    "    ]\n",
    "\n",
    "    gridSearch_rbf = GridSearchCV(SVC(), param_grid, cv = 3, scoring = 'accuracy', return_train_score = True)\n",
    "    gridSearch_rbf.fit(X_train,  Y_train)\n",
    "\n",
    "    clf_rbf = gridSearch_rbf.best_estimator_\n",
    "    print(gridSearch_rbf.best_params_)\n",
    "\n",
    "else:\n",
    "    # Build Support Vector Classifier (multiclass classifier)\n",
    "    clf_rbf = SVC(kernel = 'rbf', C = 1, gamma = 0.1, max_iter = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTICLASS CLASSIFICATION PERFORMANCE WITH A GAUSSIAN RBF KERNEL \n",
      "\n",
      "Accuracy:  \n",
      " 1.0 \n",
      "\n",
      "Confusion Matrix:  \n",
      " [[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the train set\n",
    "clf_rbf.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "Y_test_predictions_rbf = clf_rbf.predict(X_test)\n",
    "\n",
    "# Assess model accuracy\n",
    "cm = confusion_matrix(Y_test, Y_test_predictions_rbf)\n",
    "accuracy = accuracy_score(Y_test, Y_test_predictions_rbf)\n",
    "\n",
    "print('Multiclass Classification Performance With A Gaussian RBF Kernel'.upper(), '\\n')\n",
    "print('Accuracy: ', '\\n', accuracy, '\\n')\n",
    "print('Confusion Matrix: ', '\\n', cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe performance of the 3 OvR classifiers (one for each class) improved significantly by making a switch from the Linear Kernel\\nto the Gaussian RBF Kernel. \\nOn the other hand, the performance of the multiclass classifier using the Gaussian RBF Kernel was only slightly better than \\nthat of the classifier using the Linear Kernel\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The performance of the 3 OvR classifiers (one for each class) improved significantly by making a switch from the Linear Kernel\n",
    "to the Gaussian RBF Kernel. \n",
    "On the other hand, the performance of the multiclass classifier using the Gaussian RBF Kernel was only slightly better than \n",
    "that of the classifier using the Linear Kernel\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
