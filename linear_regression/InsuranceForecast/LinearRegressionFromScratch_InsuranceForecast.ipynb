{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, I will be implementing a Linear Regression algorithm from scratch to perform the task of \n",
    "# Insurance Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a pandas dataframe\n",
    "root = Path('archive')\n",
    "filename = 'insurance.csv'\n",
    "\n",
    "insurance_data = pd.read_csv(root / filename)\n",
    "insurance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region\n",
      "0   19  female  27.900         0    yes  southwest\n",
      "1   18    male  33.770         1     no  southeast\n",
      "2   28    male  33.000         3     no  southeast\n",
      "3   33    male  22.705         0     no  northwest\n",
      "4   32    male  28.880         0     no  northwest \t <class 'pandas.core.frame.DataFrame'> \n",
      "        charges\n",
      "0  16884.92400\n",
      "1   1725.55230\n",
      "2   4449.46200\n",
      "3  21984.47061\n",
      "4   3866.85520 \t <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Separate the predictors and the target variable\n",
    "predictors = ['age', 'sex', 'bmi', 'children', 'smoker', 'region']\n",
    "targets = ['charges']\n",
    "\n",
    "X = insurance_data[predictors]\n",
    "Y = insurance_data[targets]\n",
    "\n",
    "print(X.head(), '\\t', type(X), '\\n', Y.head(), '\\t',type(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 6) (1070, 1) (268, 6) (268, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the train and test set\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "train_set_size = int(0.8*len(X))\n",
    "\n",
    "X_train = X.loc[shuffled_indices[:train_set_size]]\n",
    "Y_train = Y.loc[shuffled_indices[:train_set_size]]\n",
    "X_test = X.loc[shuffled_indices[train_set_size:]]\n",
    "Y_test = Y.loc[shuffled_indices[train_set_size:]]\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = ['age','bmi','children']\n",
    "cat_attributes = ['sex','smoker','region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Normalization:  \n",
      " [[45.    25.175  2.   ]\n",
      " [36.    30.02   0.   ]\n",
      " [64.    26.885  0.   ]\n",
      " [46.    25.745  3.   ]\n",
      " [19.    31.92   0.   ]] \n",
      "\n",
      "\n",
      "After Normalization:  \n",
      " [[ 0.40451627 -0.90615783  0.75456518]\n",
      " [-0.24000585 -0.11632218 -0.92573605]\n",
      " [ 1.76517407 -0.62739231 -0.92573605]\n",
      " [ 0.47612984 -0.81323599  1.59471579]\n",
      " [-1.45743651  0.19341729 -0.92573605]] \n",
      "\n",
      "\n",
      "Feature Means:  [[39.35140187 30.73354206  1.10186916]] \n",
      "\n",
      "Feature Standard Deviations:  [[13.96383422  6.13418753  1.19026278]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the numerical attributes in the train set\n",
    "def Normalize_FitTransform(array):\n",
    "    '''This function computes the mean and std of each column in an array and normalizes the data in each column, so that \n",
    "    each column will have a mean of 0 and a std of 1.'''\n",
    "    mu = np.zeros((array.shape[1],1))\n",
    "    sigma = np.zeros((array.shape[1],1))\n",
    "    \n",
    "    for j in range(array.shape[1]):\n",
    "        mu[j] = np.mean(array[:,j])\n",
    "        sigma[j] = np.std(array[:,j])\n",
    "        \n",
    "        array[:,j] = (array[:,j] - mu[j])/sigma[j]\n",
    "    return array, mu, sigma\n",
    "\n",
    "X_train_norm_num, mu, sigma = Normalize_FitTransform(X_train[num_attributes].to_numpy())\n",
    "\n",
    "print('Before Normalization: ', '\\n', X_train[num_attributes].to_numpy()[:5], '\\n\\n')\n",
    "print('After Normalization: ', '\\n', X_train_norm_num[:5], '\\n\\n')\n",
    "print('Feature Means: ', mu.T, '\\n')\n",
    "print('Feature Standard Deviations: ', sigma.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Normalization:  \n",
      " [[45.    30.495  2.   ]\n",
      " [54.    31.9    1.   ]\n",
      " [24.    28.5    0.   ]\n",
      " [18.    25.175  0.   ]\n",
      " [52.    30.78   1.   ]] \n",
      "\n",
      "\n",
      "After Normalization:  \n",
      " [[ 0.40451627 -0.03888731  0.75456518]\n",
      " [ 1.04903839  0.19015688 -0.08558544]\n",
      " [-1.09936867 -0.36411376 -0.92573605]\n",
      " [-1.52905008 -0.90615783 -0.92573605]\n",
      " [ 0.90581125  0.00757361 -0.08558544]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the numerical attributes in the test set\n",
    "def Normalize_Transform(array, mu, sigma):\n",
    "    '''This function uses the mean and std parameters calculated on the train set and normalizes the test set using those \n",
    "    parameters'''\n",
    "    for j in range(array.shape[1]):\n",
    "        array[:,j] = (array[:,j] - mu[j])/sigma[j]\n",
    "        \n",
    "    return array\n",
    "\n",
    "X_test_norm_num = Normalize_Transform(X_test[num_attributes].to_numpy(), mu, sigma)\n",
    "\n",
    "print('Before Normalization: ', '\\n', X_test[num_attributes].to_numpy()[:5], '\\n\\n')\n",
    "print('After Normalization: ', '\\n', X_test_norm_num[:5], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Proof of Normalization\\n\\nmu = np.zeros((X_train_norm_num.shape[1],1))\\nsigma = np.zeros((X_train_norm_num.shape[1],1))\\n    \\nfor j in range(X_train_norm_num.shape[1]):\\n    mu[j] = np.mean(X_train_norm_num[:,j])\\n    sigma[j] = np.std(X_train_norm_num[:,j])\\n    \\nprint(mu)   # Mean: 0\\nprint(sigma)  # Std: 1\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Proof of Normalization\n",
    "\n",
    "mu = np.zeros((X_train_norm_num.shape[1],1))\n",
    "sigma = np.zeros((X_train_norm_num.shape[1],1))\n",
    "    \n",
    "for j in range(X_train_norm_num.shape[1]):\n",
    "    mu[j] = np.mean(X_train_norm_num[:,j])\n",
    "    sigma[j] = np.std(X_train_norm_num[:,j])\n",
    "    \n",
    "print(mu)   # Mean: 0\n",
    "print(sigma)  # Std: 1\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 8) (268, 8)\n"
     ]
    }
   ],
   "source": [
    "# Encode the categorical attributes in the train and test set\n",
    "def indexValues(listVar):\n",
    "    '''This function creates a dictionary, with keys: 0, 1 ... and values: the unique values in the list passed as argument'''\n",
    "    d = {}\n",
    "    index = 0\n",
    "    for item in listVar:\n",
    "        if item not in d.values():\n",
    "            d[index] = item\n",
    "            index += 1\n",
    "    return d\n",
    "\n",
    "def OneHotEncode(array):\n",
    "    '''This function performs the task of One Hot Encoding for the categorical attributes'''\n",
    "    finalArray = np.zeros((array.shape[0],1))  # temporarily, will remove 0's later\n",
    "\n",
    "    for j in range(array.shape[1]):\n",
    "        col = array[:,j].tolist()\n",
    "        d = indexValues(col)\n",
    "        list2D = [[0 for b in range(len(d))] for a in range(array.shape[0])]\n",
    "\n",
    "        for b in range(len(d)):\n",
    "            for a in range(array.shape[0]):\n",
    "                if col[a] == d[b]:\n",
    "                    list2D[a][b] = 1\n",
    "                else:\n",
    "                    continue          \n",
    "        featureArray = np.array(list2D)\n",
    "        finalArray = np.hstack((finalArray, featureArray))\n",
    "    finalArray = finalArray[:,1:]\n",
    "    return finalArray\n",
    "    \n",
    "X_train_encoded_cat = OneHotEncode(X_train[cat_attributes].to_numpy())\n",
    "X_test_encoded_cat = OneHotEncode(X_test[cat_attributes].to_numpy())\n",
    "print(X_train_encoded_cat.shape, X_test_encoded_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 12) (268, 12)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for the ML algorithms\n",
    "X_train_prepared = np.c_[np.ones((len(X_train),1)), X_train_norm_num, X_train_encoded_cat]\n",
    "X_test_prepared = np.c_[np.ones((len(X_test),1)), X_test_norm_num, X_test_encoded_cat]\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "print(X_train_prepared.shape, X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Normal Equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_final = np.linalg.pinv(X_train_prepared).dot(Y_train) # Some features in X_train_prepared are redundant, so the normal approach raises a Singular Matrix error \n",
    "# Test Set RMSE: 5917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  \n",
      " 321350182.6108162 \n",
      "\n",
      "Gradient:  \n",
      " [[-26625.79789114]\n",
      " [ -7130.72829994]\n",
      " [ -4683.52193663]\n",
      " [ -1440.40057639]\n",
      " [-12360.20781091]\n",
      " [-14265.59008023]\n",
      " [-13452.86296578]\n",
      " [-13172.93492536]\n",
      " [ -5965.59805741]\n",
      " [ -6299.6731446 ]\n",
      " [ -6460.69945198]\n",
      " [ -7899.82723715]]\n"
     ]
    }
   ],
   "source": [
    "def CostFunction(X,Y,theta):\n",
    "    m = X.shape[0]\n",
    "    '''\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        J += (X[i,:].dot(theta) - Y[i])**2\n",
    "    J = (1/m)*J\n",
    "    '''\n",
    "    J = (1/m)*np.sum((X.dot(theta)-Y)**2)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def Gradients(X,Y,theta):\n",
    "    m = X.shape[0]\n",
    "    '''\n",
    "    gradients = np.zeros(theta.shape)\n",
    "    for j in range(theta.shape[0]):\n",
    "        for i in range(m):\n",
    "            gradients[j] += (X[i,:].dot(theta) - Y[i])*X[i,j]\n",
    "        gradients[j] = (2/m)*gradients[j]\n",
    "    '''\n",
    "    gradients = (2/m)*(X.T.dot(X.dot(theta)-Y))\n",
    "    \n",
    "    return gradients\n",
    "\n",
    "print('Cost: ', '\\n', CostFunction(X_train_prepared, Y_train, np.random.rand(X_train_prepared.shape[1],1)), '\\n')\n",
    "print('Gradient: ', '\\n', Gradients(X_train_prepared, Y_train, np.random.rand(X_train_prepared.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchGradientDescent(X_train,Y_train,max_iters = 40000,alpha = 0.1, tolerance = 0.0001):\n",
    "    m = X_train.shape[0]\n",
    "    theta = np.zeros((X_train.shape[1],1))\n",
    "    cost_history = []\n",
    "    previous_step_size = 1\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iters and previous_step_size > tolerance:\n",
    "        cost = CostFunction(X_train, Y_train, theta)\n",
    "        cost_history.append(cost)\n",
    "        previous_theta = theta\n",
    "        \n",
    "        theta = theta - (alpha/m)*Gradients(X_train, Y_train, previous_theta)\n",
    "        \n",
    "        previous_step_size = np.linalg.norm((theta - previous_theta))\n",
    "        iteration += 1\n",
    "    \n",
    "    print('The Local Minima occurs at: ', theta, 'at ', iteration, 'iterations.')\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StochasticGradientDescent(X_train, Y_train, epochs = 100, alpha = 0.1, tolerance = 0.0001, batch_size = 1):\n",
    "    m = X_train.shape[0]\n",
    "    theta = np.zeros((X_train.shape[1],1))\n",
    "    cost_history = []\n",
    "    previous_step_size = 1\n",
    "    epoch = 0\n",
    "    \n",
    "    while epoch < epochs and previous_step_size > tolerance:\n",
    "        shuffled_indices = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[shuffled_indices]\n",
    "        Y_train = Y_train[shuffled_indices]\n",
    "        \n",
    "        for i in range(m):\n",
    "            cost = CostFunction(X_train,Y_train,theta)\n",
    "            cost_history.append(cost)\n",
    "            previous_theta = theta\n",
    "            \n",
    "            theta = theta - (alpha/m)*Gradients(np.array(X_train)[i:i+batch_size,:], np.array(Y_train)[i:i+batch_size], previous_theta)\n",
    "            \n",
    "            previous_step_size = np.linalg.norm((theta - previous_theta))\n",
    "        \n",
    "        epoch += 1\n",
    "            \n",
    "    print('The Local Minima occurs at: ', theta, 'at ', epoch, 'epochs.')\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniBatchGradientDescent(X_train, Y_train, epochs = 100000, alpha = 0.1, tolerance = 0.0001, batch_size = 100):\n",
    "    m = X_train.shape[0]\n",
    "    theta = np.random.rand(X_train.shape[1],1)\n",
    "    cost_history = []\n",
    "    previous_step_size = 1\n",
    "    epoch = 0\n",
    "    \n",
    "    while epoch < epochs and previous_step_size > tolerance:\n",
    "        shuffled_indices = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[shuffled_indices]\n",
    "        Y_train = Y_train[shuffled_indices]\n",
    "        \n",
    "        \n",
    "        cost = CostFunction(X_train,Y_train,theta)\n",
    "        cost_history.append(cost)\n",
    "        previous_theta = theta\n",
    "            \n",
    "        theta = theta - (alpha/m)*Gradients(np.array(X_train)[:batch_size,:], np.array(Y_train)[:batch_size], previous_theta)\n",
    "            \n",
    "        previous_step_size = np.linalg.norm((theta - previous_theta))\n",
    "        \n",
    "        epoch += 1\n",
    "            \n",
    "    print('The Local Minima occurs at: ', theta, 'at ', epoch, 'epochs.')\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Local Minima occurs at:  [[ 8990.32233579]\n",
      " [ 3643.31241979]\n",
      " [ 1985.8126083 ]\n",
      " [  575.76803326]\n",
      " [ 4509.42993538]\n",
      " [ 4480.89240041]\n",
      " [-7271.16065004]\n",
      " [16261.48298583]\n",
      " [ 2839.98143038]\n",
      " [ 2494.48292082]\n",
      " [ 1930.46517835]\n",
      " [ 1725.39280625]] at  100 epochs.\n"
     ]
    }
   ],
   "source": [
    "strategy = ['BGD', 'SGD', 'MBGD'][1]\n",
    "\n",
    "if strategy == 'BGD':\n",
    "    theta_final, cost_history = BatchGradientDescent(X_train_prepared, Y_train, max_iters = 100000)\n",
    "    # Train Set RMSE: 6076\n",
    "    # Test Set RMSE: 5919\n",
    "elif strategy == 'SGD':\n",
    "    theta_final, cost_history = StochasticGradientDescent(X_train_prepared, Y_train)\n",
    "    # Train Set RMSE: 6075\n",
    "    # Test Set RMSE: 5917\n",
    "elif strategy == 'MBGD':    \n",
    "    theta_final, cost_history = MiniBatchGradientDescent(X_train_prepared, Y_train)\n",
    "    # Train Set RMSE: 6076\n",
    "    # Test Set RMSE: 5921\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(len(cost_history)), np.sqrt(cost_history))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Iteration')\n",
    "#plt.savefig('{}_RMSEvsIteration'.format(strategy))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTestData(X_test, theta):\n",
    "    predictions = X_test.dot(theta)\n",
    "    return predictions\n",
    "\n",
    "Y_test_predictions = predictTestData(X_test_prepared, theta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance: \n",
      "\t MSE:  38879121.34523096\n",
      "\t RMSE:  6235.312449687743 \n",
      "\n",
      "Train Set Performance: \n",
      "\t 5997.037156551076\n"
     ]
    }
   ],
   "source": [
    "def RMSE(Y_test, Y_test_predictions):\n",
    "    '''This function computes the Mean Square Error (MSE) and the Root Mean Square Error (RMSE)'''\n",
    "    mse = (1/len(Y_test))*(np.sum((Y_test - Y_test_predictions)**2))\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse, rmse\n",
    "\n",
    "mse, rmse = RMSE(Y_test, Y_test_predictions)\n",
    "print('Test Set Performance: ')\n",
    "print('\\t', 'MSE: ', mse)\n",
    "print('\\t','RMSE: ', rmse, '\\n')\n",
    "\n",
    "print('Train Set Performance: ')\n",
    "print('\\t', np.sqrt(cost_history[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
